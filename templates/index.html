<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Text Summarizer</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3"
      crossorigin="anonymous"
    />
<style>
*{
    background-color: azure;
}
.body{
    background-color: azure;
}
.header{
    text-align: center;
    word-spacing: 10%;
    height: fit-content;
    color:#404607;
     width:100%; 
     height:10%;
     font-size: 23px;
     font-family:Comic Sans MS;
}
#para{
    justify-content: baseline;
    text-align: justify;
    flex-direction: column;
    flex: auto;
    color: #2AAD0C;
    padding-left: 2em;
    padding-right: 2em;
    line-height-step: 3em;
    font-size: 25px;
    font-family: Comic Sans MS;
}
.center{
    padding-top: 0.6em;
    font-size:60px;
    font-family:forte;
    text-align:center; 
    width:"600px"
}
#pad{
    padding-left: 2em;
    padding-top: 0.6em;
    padding-bottom: 0.5em;
}
#textare{
    padding-left: 3em;
}
.lable{
    color:#15D0BE;
    font-size: 25px;
    font-family:Comic Sans MS;
    padding-bottom: 0.4em;

}
#Home,#Abstract,#Referances,#Model{
    width: 100%;
    height: 720px;
   border: 1px solid bisque; 
}
#par{
    justify-content: baseline;
    text-align: justify;
    flex-direction: column;
    flex: auto;
    color: #a28e0c;
    padding-left: 2em;
    padding-right: 2em;
    line-height-step: 3em;
    font-size: 25px;
    font-family: Comic Sans MS;
    padding-bottom: 1em;
}
#padd{
    padding-left: 2em;
    padding-top: 0.4em;
}
.list{
    font-size: 25px;
    font-family: Comic Sans MS;
    justify-content: baseline;
    text-align: justify;
    line-height-step: 5em;
    font-size: 20px;
    padding-left: 2em;
    padding-right: 2em;
    line-height: 1.8;
    padding-bottom: 2em;
}
#first{
    color: #2AAD0C;
}
#second{
    color: #15D0BE;
}
#third{
    color: rgb(167, 110, 19);
}
#pa{
    text-align: center;
    justify-content: center;
    padding-top:0.4em;
    padding-bottom: 5em;
}
.imm{
    justify-content: center;
    display: block;
    margin-left: 8%;
    margin-right: auto;
}
</style>
<script>
document.querySelectorAll('a[href^="#"]').forEach(anchor => {
    anchor.addEventListener("click",function(e){
        document.querySelector(this.getAttribute("href")).scrollIntoView({
            behavior:"smooth"
        });
    });
});
</script>
</head>
<body class="body">
    <div id="Home">
        <h1 class="center"><font color="#15D0BE">Text</font><font color="#BDD015"> Summarizer</font></h1>
        <table class="header" >
            <tr >
                <td><a href="#Home">Home</a></td>
                <td><a href="#Abstract">Abstract</a></td>
                <td><a href="#Model">Model</a></td>
                <td><a href="#Referances">Referances</a> </td>
            </tr>
        </table>
        <form action="/summarize" method="post">
            <div id="textare">
                <br>
                <h3 class="lable">Enter text to Summarize: </h3>
                <div>
                    <textarea name="data" id="idd" cols="150" rows="13"></textarea>
                </div>
                <button type="submit" class="btn btn-outline-primary">Summarize</button><br>
            </div>
        </form>
    </div>
   <div id="Abstract">
    <h2 id="pad"><font color="#15D0BE" size="10px" align:"left" style="font-family:Comic Sans MS">Abst<font color="#BDD015">ract</font> </font></h2>
    <p id="para">Nowadays there is a huge demand for text summarization tools since the main objective of a text summarization system is 
         to identify the most important information from the given text and present it to the end users. In this project, we have deployed
         a web application that takes any general paragraph as input to give a summarized version of that particular paragraph by 
         identifying text features and also translating the summarized text into any language. In order, to summarize the text we have 
         proposed a hybrid model that is based upon Luhn and Textrank algorithms which are extractive summarization techniques and the 
         Pegasus model which is an abstractive summarization technique. This hybrid model was also compared with BERT, XLNet, and GPT2 
         models based on their ROGUE scores. The generated optimal paragraph is sent as input to the translator which translates the 
         summarized text into any language. In this project, we have also tried to achieve better results from the proposed hybrid model 
         when compared to other existing models. Firstly, the text rank algorithm is used to rank the sentences based on their priority, 
         and then abstractive summarization is performed on this paragraph using the Pegasus model to generate a new summary with good 
         context which is then passed on to the Luhn algorithm which generates the final optimal paragraph. This text summarizer deployed 
         using a web app has various applications such as newsletters, social media content generation, etc.
    </p>
    <h4 id="padd"><font color="#15D0BE" size="6px" align:"left" style="font-family:Comic Sans MS">Keywords </font></h4>
    <p id="par">Pegasus, BERT, XLNet, GPT2, abstractive summarization, TextRank, ROGUE, Luhn.</p>
   </div>
   <div id="Model">
    <h2 id="pad"><font color="#15D0BE" size="10px" align:"left" style="font-family:Comic Sans MS">Working<font color="#BDD015"> Model</font></font></h2>
    <div class="imm"> 
        <img src="{{model_img}}" alt="">
    </div>
    <h2 id="pa"><font color="#BDD015"size="6px" align:"left" style="font-family:Comic Sans MS">Framework <font color="#15D0BE" >of the</font> proposed <font color="#15D0BE" > hybrid model</font></font></h2>
   </div>
   <div id="References">
    <h2 id="pad"><font color="#15D0BE" size="10px" align:"left" style="font-family:Comic Sans MS">Refera<font color="#BDD015">nces</font></font></h2>
    <div class="list">
        <ol>
            <div id="first">
                <li>Ma, T., Pan, Q., Rong, H., Qian, Y., Tian, Y., & Al-Nabhan, N. (2021). T-bertsum: Topic-aware text summarization based on bert. IEEE Transactions on Computational Social Systems, 9(3), 879-890.        </li>
                <li>Mrinalini, K., Vijayalakshmi, P., & Nagarajan, T. (2022). SBSim: A Sentence-BERT Similarity-Based Evaluation Metric for Indian Language Neural Machine Translation Systems. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 30, 1396-1406.        </li>
                <li>Wang, Q., Liu, P., Zhu, Z., Yin, H., Zhang, Q., & Zhang, L. (2019). A text abstraction summary model based on BERT word embedding and reinforcement learning. Applied Sciences, 9(21), 4701.</li>
                <li>Li, P., Yu, J., Chen, J., & Guo, B. (2021). HG-News: News Headline Generation Based on a Generative Pre-Training Model. IEEE Access, 9, 110039-110046.</li>
                <li>Gidiotis, A., & Tsoumakas, G. (2020). A divide-and-conquer approach to the summarization of long documents. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 28, 3029-3040. </li>
                <li>Akhtar, N., Beg, M. S., & Javed, H. (2019, August). TextRank enhanced topic model for query focussed text summarization. In 2019 Twelfth International Conference on Contemporary Computing (IC3) (pp. 1-6). IEEE. </li>
                <li>Tan, X., Zhuang, M., Lu, X., & Mao, T. (2021). An analysis of the emotional evolution of large-scale internet public opinion events based on the BERT-LDA hybrid model. IEEE Access, 9, 15860-15871.</li>
                <li>Mridha, M. F., Lima, A. A., Nur, K., Das, S. C., Hasan, M., & Kabir, M. M. (2021). A survey of automatic text summarization: Progress, process and challenges. IEEE Access, 9, 156043-156070.</li>
                <li>Vathsala, M. K., & Holi, G. (2020). RNN based machine translation and transliteration for Twitter data. International Journal of Speech Technology, 23(3), 499-504.</li>
                <li>Bawa, S., & Kumar, M. (2021). A comprehensive survey on machine translation for English, Hindi and Sanskrit languages. Journal of Ambient Intelligence and Humanized Computing, 1-34.</li>    
            </div>
            <div id="second">
                <li>Ning, J., & Ban, H. (2021). Design and Testing of Automatic Machine Translation System Based on Chinese-English Phrase Translation. Mobile Information Systems, 2021.</li>
                <li>Ke, X. (2022). English synchronous real-time translation method based on reinforcement learning. Wireless Networks, 1-13.</li>
                <li>Kano, T., Sakti, S., & Nakamura, S. (2020). End-to-end speech translation with transcoding by multi-task learning for distant language pairs. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 28, 1342-1355.</li>
                <li>Heo, Y., Kang, S., & Yoo, D. (2019). Multimodal neural machine translation with weakly labeled images. IEEE Access, 7, 54042-54053.</li>
                <li>Sen, O., Fuad, M., Islam, M. N., Rabbi, J., Masud, M., Hasan, M. K., ... & Iftee, M. A. R. (2022). Bangla Natural Language Processing: A Comprehensive Analysis of Classical, Machine Learning, and Deep Learning Based Methods. IEEE Access.</li>
                <li>Mallick, C., Das, A. K., Dutta, M., Das, A. K., & Sarkar, A. (2019). Graph-based text summarization using modified TextRank. In Soft computing in data analytics (pp. 137-146). Springer, Singapore.</li>
                <li>Zeng, H., & Chen, G. (2020, December). Unsupervised extractive summarization based on context information. In 2020 IEEE 6th International Conference on Computer and Communications (ICCC) (pp. 1651-1655). IEEE.</li>
                <li>Xie, Q., Bishop, J. A., Tiwari, P., & Ananiadou, S. (2022). Pre-trained language models with domain knowledge for biomedical extractive summarization. Knowledge-Based Systems, 109460.</li>
                <li>Qaroush, A., Farha, I. A., Ghanem, W., Washaha, M., & Maali, E. (2021). An efficient single document Arabic text summarization using a combination of statistical and semantic features. Journal of King Saud University-Computer and Information Sciences, 33(6), 677-692.</li>
                <li>Iwasaki, Y., Yamashita, A., Konno, Y., & Matsubayashi, K. (2019, November). Japanese abstractive text summarization using BERT. In 2019 International Conference on Technologies and Applications of Artiﬁcial Intelligence (TAAI) (pp. 1-5). IEEE </li>
                <li>Abdel-Salam, S., & Rafea, A. (2022). Performance Study on Extractive Text Summarization Using BERT Models. Information, 13(2), 67.</li>
                
            </div>
            <div id="third">
                <li>Andrabi, S. A. B., & Wahid, A. (2022). Machine translation system using deep learning for English to Urdu. Computational Intelligence and Neuroscience, 2022. </li>
                <li>Gupta, H., & Patel, M. (2021, March). Method Of Text Summarization Using Lsa And Sentence Based Topic Modelling With Bert. In 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS) (pp. 511-517). IEEE. </li>
                <li>Srikanth, A., Umasankar, A. S., Thanu, S., & Nirmala, S. J. (2020, October). Extractive text summarization using dynamic clustering and co-reference on BERT. In 2020 5th International Conference on Computing, Communication and Security (ICCCS) (pp. 1-5). IEEE.</li>
                <li>Chen, K., Zhao, T., Yang, M., Liu, L., Tamura, A., Wang, R., ... & Sumita, E. (2019). A neural approach to source dependence based context model for statistical machine translation. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 26(2), 266-280.</li>
                <li>Madhuri, J. N., & Kumar, R. G. (2019, March). Extractive text summarization using sentence ranking. In 2019 International Conference on Data Science and Communication (IconDSC) (pp. 1-3). IEEE.</li>
                <li>Chandra, R., & Kulkarni, V. (2022). Semantic and sentiment analysis of selected bhagavad gita translations using BERT-based language framework. IEEE Access, 10, 21291-21315.</li>
                <li>Xie, Q., Bishop, J. A., Tiwari, P., & Ananiadou, S. (2022). Pre-trained language models with domain knowledge for biomedical extractive summarization. Knowledge-Based Systems, 109460.</li>
                <li>Ramina, M., Darnay, N., Ludbe, C., & Dhruv, A. (2020, May). Topic level summary generation using BERT induced Abstractive Summarization Model. In 2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS) (pp. 747-752). IEEE.</li>
                <li>Sehgal, S., Kumar, B., Rampal, L., & Chaliya, A. (2019). A modification to graph based approach for extraction based automatic text summarization. In Progress in advanced computing and intelligent engineering (pp. 373-378). Springer, Singapore.</li>    
            </div>
        </ol>
    </div>
    </div>  
</body>
</html>